{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Draft\n",
    "\n",
    "## Abstract\n",
    "\n",
    "* Try different methods on combing title vectors and text vectors.\n",
    "* Concatenate text vectors made from w2v and d2v methods as final feature vectors(600d).\n",
    "* Using an Ensemble classifier(composed of three tuned estimators) to train and make predictions on the feature vectors we get.\n",
    "* Reach an over 0.94 f-1 score in test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "First, we need to import the data. Since we plan to test if using the combination of title vectors and text vectors would yield a better result, we import title corpus and text corpus seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# import all the data and split all strings to words in it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report as cr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from numpy import linspace\n",
    "df=pd.read_csv('E:/github/FakeNewsTutorials/data/fake_or_real_news.csv')\n",
    "title=np.asarray(df.title)\n",
    "text=np.asarray(df.text)\n",
    "y=np.asarray(df.label)\n",
    "textandtitlearray=np.concatenate((title,text),axis=0)\n",
    "title=[titles.lower().split() for titles in title]\n",
    "text=[texts.lower().split() for texts in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "After importing all the data we have, we preprocessed the dataset in order to filter unuseful noise and make our data more informative. In this process, we first removed all stopwords from both the title corpus and the text corpus, then lemmatized the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# Defining a preprocessing function that can lemmatize and remove stopwords from the corpus\n",
    "# preprocessing both title corpus and text corpus\n",
    "\n",
    "\n",
    "def cleanandlemmatize(tokenized,sw,punc,iflemmatize=False):\n",
    "    new_text=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    if(iflemmatize==True):\n",
    "        for review in tokenized:\n",
    "            new_text.append([lemmatizer.lemmatize(word)for word in review if word not in chain(sw,punc)])\n",
    "    else:\n",
    "        for review in tokenized:\n",
    "            new_text.append([word for word in review if word not in chain(sw,punc)]) \n",
    "    return new_text\n",
    "sw=stopwords.words('english')\n",
    "punc=punctuation\n",
    "clean_title=cleanandlemmatize(title,sw,punc,True)\n",
    "clean_text=cleanandlemmatize(text,sw,punc,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to combine titles and texts\n",
    "\n",
    "### Concatenation\n",
    "Our first notion of this issue is that we can first get two vectors, one is generated from the title corpus and the other is from text corpus, then we will concatenate these two vectors into one long vector. And then we will see if the long vector can provide more information than a single vector. The vectorization method we used was Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# train two w2v models, one trained on text corpus, the other trained on title corpus\n",
    "\n",
    "\n",
    "model1 = Word2Vec(clean_title,\n",
    "                       size = 300,\n",
    "                       window = 5,\n",
    "                       min_count = 0,\n",
    "                       sg = 0,\n",
    "                       alpha = 0.025,\n",
    "                       iter=10,\n",
    "                       batch_words = 10000)\n",
    "model2 = Word2Vec(clean_text,\n",
    "                        size = 300,\n",
    "                        window = 5,\n",
    "                        min_count = 1,\n",
    "                        sg = 0,\n",
    "                        alpha = 0.025,\n",
    "                        iter=10,\n",
    "                        batch_words = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# Develope doc vectors from word vectors by taking average of word vectors\n",
    "\n",
    "title_list=[]\n",
    "text_list=[]\n",
    "deleteindex=[]\n",
    "deletecount=0\n",
    "for title,text in zip(clean_title,clean_text):\n",
    "   count=0\n",
    "   init_vec=np.zeros([300,])\n",
    "   init_vec1=np.zeros([300,])\n",
    "   for tiword,teword in zip(title,text):\n",
    "       init_vec+=model1.wv[tiword]\n",
    "       init_vec1+=model2.wv[teword]\n",
    "       count+=1\n",
    "   if(count==0):\n",
    "       deleteindex.append(deletecount)\n",
    "   else:\n",
    "       init_vec/=count\n",
    "       init_vec1/=count\n",
    "       title_list.append(init_vec)\n",
    "       text_list.append(init_vec1)\n",
    "   deletecount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 600)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# concatenate title vectors and text vectors\n",
    "\n",
    "final_y=np.delete(y,deleteindex)\n",
    "titleandtext_list=[]\n",
    "for title,text  in zip(title_list,text_list):\n",
    "    titleandtext_list.append([*list(title),*list(text)])\n",
    "titleandtext_array=np.asarray(titleandtext_list)\n",
    "titleandtext_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the vector, the next step is to find an accurate classifier, in order to do so, we tried four different kinds of classification methods which are Logistic Regression, Random Forest, XGBoost and SVC( we also intended to try multinomial naive Bayesian model, however it seems that MNB model doesn't take negative inputs and some elements in our vectors are inevitably negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.83 (+/- 0.00) [LR]\n",
      "text_f1_score: 0.78 (+/- 0.00) [RF]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.83 (+/- 0.01) [XGB]\n",
      "text_f1_score: 0.82 (+/- 0.00) [SVC]\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# test the concatenated vectors on four different classifiers(using crossvalidation)\n",
    "# evaluate their mean value and std of f-1 values\n",
    "\n",
    "realnumber_y=[1]*6298\n",
    "count=0\n",
    "for word in final_y:\n",
    "    if(word=='FAKE'):\n",
    "        realnumber_y[count]=0\n",
    "    else:\n",
    "        realnumber_y[count]=1\n",
    "    count+=1\n",
    "clf1=LogisticRegression()\n",
    "clf2=RandomForestClassifier()\n",
    "clf3=XGBClassifier()\n",
    "clf4=SVC(probability=True)\n",
    "\n",
    "for clf,label in zip([clf1,clf2,clf3,clf4],['LR','RF','XGB','SVC']):\n",
    "    scores=cross_validation.cross_val_score(clf,titleandtext_array,realnumber_y,scoring='f1')\n",
    "    print(\"text_f1_score: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, from the results we got from the last two weeks we know that models that trained solely on the text vectors have a performance that can reach about 0.9 on f-1 score. So we trained all four vectors we used above again, but this time the training provess only used text vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.90 (+/- 0.00) [LR]\n",
      "text_f1_score: 0.88 (+/- 0.01) [RF]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.90 (+/- 0.00) [XGB]\n",
      "text_f1_score: 0.88 (+/- 0.00) [SVC]\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# test the text vectors on four different classifiers(using crossvalidation)\n",
    "# evaluate their mean value and std of f-1 values\n",
    "\n",
    "\n",
    "number_list=[]\n",
    "deleteindex=[]\n",
    "deletecount=0\n",
    "for review in clean_text:\n",
    "    count=0\n",
    "    init_vec=np.zeros([300,])\n",
    "    for word in review:\n",
    "        init_vec+=model2.wv[word]\n",
    "        count+=1\n",
    "    if(count==0):\n",
    "        deleteindex.append(deletecount)\n",
    "    else:\n",
    "        init_vec/=count\n",
    "        number_list.append(init_vec)\n",
    "    deletecount+=1\n",
    "w_text_array=np.asarray(number_list)\n",
    "final_y=np.delete(y,deleteindex)\n",
    "realnumber_y=[1]*6299\n",
    "count=0\n",
    "for word in final_y:\n",
    "    if(word=='FAKE'):\n",
    "        realnumber_y[count]=0\n",
    "    else:\n",
    "        realnumber_y[count]=1\n",
    "    count+=1\n",
    "for clf,label in zip([clf1,clf2,clf3,clf4],['LR','RF','XGB','SVC']):\n",
    "    scores=cross_validation.cross_val_score(clf,w_text_array,realnumber_y,scoring='f1')\n",
    "    print(\"text_f1_score: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very frustrating that the concatenated vector's performance is even worse than the text vector, which means that the concatenation we did on the vectors is not a good way of improving the overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Weighted Average\n",
    "\n",
    "Our second solution to this issue is that first we can seperately build two models, one is trained on the text corpus and the other is trained on title corpus, then we take the weighted average of these two different models' results. The weights of different models will be decided based on their classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have the performance of text corpus based model, now we only need to evaluate the model trained on title corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.57 (+/- 0.01) [LR]\n",
      "text_f1_score: 0.60 (+/- 0.00) [RF]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.65 (+/- 0.01) [XGB]\n",
      "text_f1_score: 0.52 (+/- 0.00) [SVC]\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# test the title vectors on four different classifiers(using crossvalidation)\n",
    "# evaluate their mean value and std of f-1 values\n",
    "\n",
    "\n",
    "number_list=[]\n",
    "deleteindex=[]\n",
    "deletecount=0\n",
    "for review in clean_title:\n",
    "    count=0\n",
    "    init_vec=np.zeros([300,])\n",
    "    for word in review:\n",
    "        init_vec+=model1.wv[word]\n",
    "        count+=1\n",
    "    if(count==0):\n",
    "        deleteindex.append(deletecount)\n",
    "    else:\n",
    "        init_vec/=count\n",
    "        number_list.append(init_vec)\n",
    "    deletecount+=1\n",
    "w_title_array=np.asarray(number_list)\n",
    "final_y=np.delete(y,deleteindex)\n",
    "realnumber_y=[1]*6334\n",
    "count=0\n",
    "for word in final_y:\n",
    "    if(word=='FAKE'):\n",
    "        realnumber_y[count]=0\n",
    "    else:\n",
    "        realnumber_y[count]=1\n",
    "    count+=1\n",
    "for clf,label in zip([clf1,clf2,clf3,clf4],['LR','RF','XGB','SVC']):\n",
    "    scores=cross_validation.cross_val_score(clf,w_title_array,realnumber_y,scoring='f1')\n",
    "    print(\"text_f1_score: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine results from different models, we built an ensemble classifier to calculate the weighted average of different models'results, the class of EnsembleClassifier we built shows as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# Define the EnsembleClassifier class\n",
    "\n",
    "class EnsembleClassifier():\n",
    "    \n",
    "    def __init__(self,textclfs,titleclfs,weights):\n",
    "        self.textclfs=textclfs\n",
    "        self.titleclfs=titleclfs\n",
    "        self.weights=weights\n",
    "\n",
    "    def fit(self,doc_vec,title_vec, y):\n",
    "        for text_clf in self.textclfs:\n",
    "            text_clf.fit(doc_vec,y)\n",
    "        for title_clf in self.titleclfs:\n",
    "            title_clf.fit(title_vec,y)\n",
    "        #print(\"fitting process is over\")\n",
    "    def predict(self, title_vec,doc_vec):\n",
    "        \n",
    "        print(\"predict process begins\")\n",
    "        avg=self.predict_proba(doc_vec,title_vec)\n",
    "        results=[]\n",
    "        for item in avg:\n",
    "          if(item[0]>item[1]):\n",
    "              results.append('FAKE')\n",
    "          else:\n",
    "              results.append('REAL')\n",
    "        print(\"predict process is over\")\n",
    "        return np.asarray(results)\n",
    "\n",
    "    def predict_proba(self, doc_vec, title_vec):\n",
    "        self.probas_ = [np.array(text_clf.predict_proba(doc_vec),dtype='float') for text_clf in self.textclfs]\n",
    "        for title_clf in self.titleclfs:\n",
    "            self.probas_.append(title_clf.predict_proba(title_vec))\n",
    "        avg = np.average(self.probas_, axis=0, weights=self.weights)\n",
    "#        for result,weight in zip(self.probas_,self.weights):\n",
    "#            sumresult+=result*weight\n",
    "#            sumweight+=weight\n",
    "#        avg=sumresult/sumweight\n",
    "        print(avg)\n",
    "        return avg  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initiation of this EnsembleClassifier takes three parameters, the first is the list of classifiers we want to train with text corpus, the second is the list of models we want to train with title corpus, the third is the list of weights for all classifiers we provided in the first two parameters. From the result of our previous tests, we can see that the best classifier for text corpus and title corpus is Logistic Regression and XGBoost respectively. So we used these two classifiers to build our Ensemble Classifier, and since the f-1  score of title corpus based model is fairly low, we set its weight to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# divide title corpus, text corpus and labels into training set and testing set\n",
    "\n",
    "\n",
    "title_list=[]\n",
    "text_list=[]\n",
    "deleteindex=[]\n",
    "deletecount=0\n",
    "for title,text in zip(clean_title,clean_text):\n",
    "   count=0\n",
    "   init_vec=np.zeros([300,])\n",
    "   init_vec1=np.zeros([300,])\n",
    "   for tiword,teword in zip(title,text):\n",
    "       init_vec+=model1.wv[tiword]\n",
    "       init_vec1+=model2.wv[teword]\n",
    "       count+=1\n",
    "   if(count==0):\n",
    "       deleteindex.append(deletecount)\n",
    "   else:\n",
    "       init_vec/=count\n",
    "       init_vec1/=count\n",
    "       title_list.append(init_vec)\n",
    "       text_list.append(init_vec1)\n",
    "   deletecount+=1\n",
    "final_y=np.delete(y,deleteindex)\n",
    "titleandtext_list=[]\n",
    "for title,text  in zip(title_list,text_list):\n",
    "    titleandtext_list.append([*list(title),*list(text)])\n",
    "teandti_train,teandti_test,y_train,y_test=tts(titleandtext_list,final_y,test_size=0.33,random_state=22)\n",
    "ultraclf=EnsembleClassifier(textclfs=[clf1],titleclfs=[clf3],weights=[1,0.5])\n",
    "text_train=[]\n",
    "title_train=[]\n",
    "text_test=[]\n",
    "title_test=[]\n",
    "for train in teandti_train:\n",
    "    title_train.append(train[0:300])\n",
    "    text_train.append(train[300:])\n",
    "for test in teandti_test:\n",
    "    title_test.append(test[0:300])\n",
    "    text_test.append(test[300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict process begins\n",
      "[[0.23497969 0.7650203 ]\n",
      " [0.84014488 0.15985512]\n",
      " [0.34926832 0.65073168]\n",
      " ...\n",
      " [0.06299413 0.93700587]\n",
      " [0.6407512  0.3592488 ]\n",
      " [0.19392919 0.80607081]]\n",
      "predict process is over\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE     0.8373    0.8332    0.8352      1025\n",
      "       REAL     0.8385    0.8425    0.8405      1054\n",
      "\n",
      "avg / total     0.8379    0.8379    0.8379      2079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# using the ensemble classifier to trian on title train corpus and text train corpus\n",
    "# make predicitons on title test corpus and text test corpus\n",
    "# evaluate its performance\n",
    "\n",
    "text_train=np.asarray(text_train)\n",
    "text_test=np.asarray(text_test)\n",
    "title_train=np.asarray(title_train)\n",
    "title_test=np.asarray(title_test)\n",
    "ultraclf.fit(text_train,title_train,y_train)\n",
    "prediction=ultraclf.predict(title_test,text_test)\n",
    "target_names=['FAKE','REAL']\n",
    "print(cr(y_test,prediction,target_names=target_names,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the combination of title and text yields no better performance than solely using text. We also repeated this same experiment on the TFIDF vectors of text and titles, and the result shows no difference than this one. So we decided to give up on using title vectors and try different ways of making more informative feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How to combine results of different vectorization method\n",
    "### Concatenation\n",
    "We think the reason why using the combinations of text vectors and title vectors shows no better performance is that the information provided by titles is either too few to influence the final resullt or too conflicting with those provided by the text. So we think maybe using the combinations of different text vectors made by differetn vectorization methods would show more information, and the first way of combination we tried was still concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# Develope doc vectors from word vectors by taking average of word vectors\n",
    "\n",
    "number_list=[]\n",
    "deleteindex=[]\n",
    "deletecount=0\n",
    "for review in clean_text:\n",
    "    count=0\n",
    "    init_vec=np.zeros([300,])\n",
    "    for word in review:\n",
    "        init_vec+=model2.wv[word]\n",
    "        count+=1\n",
    "    if(count==0):\n",
    "        deleteindex.append(deletecount)\n",
    "    else:\n",
    "        init_vec/=count\n",
    "        number_list.append(init_vec)\n",
    "    deletecount+=1\n",
    "w_text_array=np.asarray(number_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\gensim\\models\\doc2vec.py:531: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "F:\\Anaconda\\lib\\site-packages\\gensim\\models\\doc2vec.py:535: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# take doc vectors by using d2v method\n",
    "\n",
    "tagged_docs = [TaggedDocument(doc, tags=[idx]) for idx, doc in enumerate(clean_text)]\n",
    "# model built on text area\n",
    "doc2vec1 = Doc2Vec(tagged_docs,size=300, window=5, min_count=5, dm = 0.5, iter=10)\n",
    "doc2vec1.train(tagged_docs, epochs=50, total_examples=doc2vec1.corpus_count)\n",
    "new_list2=[]\n",
    "for i in range(doc2vec1.docvecs.count):\n",
    "    new_list2.append(doc2vec1.docvecs[i])\n",
    "text_array=np.asarray(new_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# process the lael array and doc array made from d2v, so that all three arrays can have the same shape.\n",
    "\n",
    "final_y=np.delete(y,deleteindex)\n",
    "d_text_array=np.delete(text_array,deleteindex,axis=0)\n",
    "wordanddoc_list=[]\n",
    "for word,doc  in zip(w_text_array,d_text_array):\n",
    "    wordanddoc_list.append([*list(word),*list(doc)])\n",
    "    \n",
    "wordanddoc_array=np.asarray(wordanddoc_list)\n",
    "\n",
    "realnumber_y=[1]*6299\n",
    "count=0\n",
    "for word in final_y:\n",
    "    if(word=='FAKE'):\n",
    "        realnumber_y[count]=0\n",
    "    else:\n",
    "        realnumber_y[count]=1\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.93 (+/- 0.00) [LR]\n",
      "text_f1_score: 0.87 (+/- 0.01) [RF]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_f1_score: 0.91 (+/- 0.01) [XGB]\n",
      "text_f1_score: 0.93 (+/- 0.00) [SVC]\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# test the concatenate vectors on four classifiers.\n",
    "\n",
    "clf1=LogisticRegression()\n",
    "clf2=RandomForestClassifier()\n",
    "clf3=XGBClassifier()\n",
    "clf4=SVC(probability=True)\n",
    "\n",
    "for clf,label in zip([clf1,clf2,clf3,clf4],['LR','RF','XGB','SVC']):\n",
    "    scores=cross_validation.cross_val_score(clf,wordanddoc_array,realnumber_y,scoring='f1')\n",
    "    print(\"text_f1_score: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the results are so much better than only using text vectors, all the four classifiers we tested got a considerable amount of improvement which means this kind of combination is actually working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Ensemble Voting Classifier\n",
    "Now we have our desired vectors, we need to consider which classifier we need to use. Then  we realized in stead of just using one classifier, maybe using a voting classifier which can actually take several different classifiers' results into account and then give a final classification would be our best choice. And luckily we found that with some small tunes on the parameters, the Ensemble Classifier class we just created can do the trick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to take those classifiers whose performance are in the top three list, by the previous result, these classifiers are clf1(Logistic Regression), clf3(XGBoost) and clf4(SVC). Since we only use vectors build from text, we passed all these three models as the first parameter to the EnsembleClassifier, and set all their weights to be 1. But Before that, we plan to use random grid search on each classifier to tune their hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# setting three sets of parameters for random grid search\n",
    "# random_grid1 for clf1,random_grid3 for clf3,random_grid4 for clf4\n",
    "\n",
    "c=np.linspace(1,50,200)\n",
    "random_grid1={'C':c}\n",
    "\n",
    "\n",
    "random_grid3 = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': np.linspace(0.1,5,100),\n",
    "        'max_depth': list(range(1,9,1)),\n",
    "        'n_estimators': list(range(200,2000,10))\n",
    "        }\n",
    "\n",
    "\n",
    "random_grid4= {'C':linspace(1,50,200),'gamma':linspace(0.001,1,200), 'kernel':['linear','rbf']}\n",
    "n_iter_search=100\n",
    "random_search1=RandomizedSearchCV(clf1,cv=5,param_distributions=random_grid1,n_iter=n_iter_search,return_train_score=True,n_jobs=6)\n",
    "random_search3=RandomizedSearchCV(clf3,cv=5,param_distributions=random_grid3,n_iter=n_iter_search,return_train_score=True,n_jobs=6)\n",
    "random_search4=RandomizedSearchCV(clf4,cv=5,param_distributions=random_grid4,n_iter=n_iter_search,return_train_score=True,n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# divide the whole corpus into three parts: validation set(25%), test set(25%) and training set(25%)\n",
    "test_size=0.25\n",
    "validation_size=0.25\n",
    "test_validation_size=test_size+validation_size\n",
    "test_size1=test_size/test_validation_size\n",
    "x_train,x_testandvalid,y_train,y_testandvalid=tts(wordanddoc_array,final_y,test_size=test_validation_size,random_state=22)\n",
    "x_valid,x_test,y_valid,y_test=tts(x_testandvalid,y_testandvalid,test_size=test_size1,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=6,\n",
       "          param_distributions={'C': array([ 1.     ,  1.24623, ..., 49.75377, 50.     ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search1.fit(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=6,\n",
       "          param_distributions={'min_child_weight': [1, 5, 10], 'gamma': array([0.1    , 0.14949, ..., 4.95051, 5.     ]), 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8], 'n_estimators': [200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 46...30, 1840, 1850, 1860, 1870, 1880, 1890, 1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search3.fit(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=6,\n",
       "          param_distributions={'C': array([ 1.     ,  1.24623, ..., 49.75377, 50.     ]), 'gamma': array([0.001  , 0.00602, ..., 0.99498, 1.     ]), 'kernel': ['linear', 'rbf']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search4.fit(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict process begins\n",
      "[[0.57315296 0.42684704]\n",
      " [0.46745261 0.53254738]\n",
      " [0.02940278 0.97059722]\n",
      " ...\n",
      " [0.23963596 0.76036404]\n",
      " [0.15133448 0.84866552]\n",
      " [0.24705431 0.75294569]]\n",
      "predict process is over\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE     0.9345    0.9513    0.9428       780\n",
      "       REAL     0.9513    0.9346    0.9429       795\n",
      "\n",
      "avg / total     0.9430    0.9429    0.9429      1575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# assign all three best estimators of three random gridsearch to clf1, clf3 and clf4\n",
    "# use the ensemble classifier to train and test on the training set and test set.\n",
    "# evaluate its performance.\n",
    "\n",
    "clf1=random_search1.best_estimator_\n",
    "clf3=random_search3.best_estimator_\n",
    "clf4=random_search4.best_estimator_\n",
    "ultraclf=EnsembleClassifier(textclfs=[clf1,clf3,clf4],titleclfs=[],weights=[1,1,1])\n",
    "ultraclf.fit(x_train,x_train,y_train)\n",
    "prediction=ultraclf.predict(x_test,x_test)\n",
    "target_names=['FAKE','REAL']\n",
    "print(cr(y_test,prediction,target_names=target_names,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result given by the voting classifier is even better than every single one of its component classifier, it reaches an f-1 score of over 0.94 as shown above. Now as always, we'll present the confusion matrix of the result from our best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# make a function that can plot cofusion matrix\n",
    "#This is a compact version of the orginal function(The original function is here:http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm,classes,title='Confusion Matrix',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEmCAYAAAA0k8gFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4JTlD02YHNLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1bb9e0128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MengZe Zhang 2018-9-23\n",
    "# plot the confusion matrix\n",
    "\n",
    "%matplotlib inline\n",
    "cm=metrics.confusion_matrix(y_test,prediction,target_names)\n",
    "plot_confusion_matrix(cm,classes=target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
